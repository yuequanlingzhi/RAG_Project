# 12.9更新

1. 更换了词向量嵌入模型，现在的模型更轻量而且对语义匹配的适配更好
2. 考虑到大模型本地部署需要的算力和显存较多（我的电脑跑不动），我直接采用api-key调用3.5-turbo了
3. 经测试，SimCES自监督微调的效果不佳，主要是他只是将相同句子的label标记为1，负样本缺失，而且相似的样本也缺少，微调后的效果还不如原来的，换成**multi-qa-MiniLM-L6-cos-v1**后更是如此
4. 如果想进一步微调提升嵌入模型的表现，我们可以自己标注那几个文档的数据，我已经写好了标注的脚本**label.py**。大致思路是，随机从一个chunk中截取一段文本出来，丢到模型中，输出前n个相似的chunk，我们自己将截取文本与其匹配，相似的标记1，不相似的标记0。标注完数据后再用标注好的数据去微调，微调代码整合到**finetune.ipynb**中了，应该可以直接跑通，可能需要下几个包，按照提示pip就好。
5. 标记的方法可以参照下面，这里设定了n=5，他一次输出前5个结果，第一个是原文可以标注1（正样本），后面的文段都没有匹配的，就标注0（负样本），输入q标注结束，标注会自动读取已保存好的标注数据并在末尾添加。
   ```
   随机文段：程中，应使用飞机维护手册或附件说明书所规
   
   Chunk:
    在维护过程中，应使用飞机维护手册或附件说明书所规定牌号的液压油
   Score: 0.20118004083633423
   
   Chunk:
    两个斜齿轮中，一个由手摇把手带动，另一个装在磨擦离合器套轴上，并通过减速机构增速，带动飞轮旋转
   Score: 0.3988851010799408
   
   Chunk:
    飞机线路图手册记录飞机各个系统所有终端的实际线路连接的展示，
   通过导线/电缆将连接器、终端块将飞机系统连接在一起，假想线路除外
   飞机线路图手册没有记录飞机各个系统所有终端的实际线路连接的线路，记录在交叉索引清单中
   Score: 0.40233537554740906
   
   Chunk:
    模式强调先进性，因此，APS理论中的模式特别注重先进维修技术、方法和手段在维修工作中的运用
   Score: 0.4052748680114746
   
   Chunk:
    经调查发现，在更换燃调过程中，其中两个螺杆难以接近，工作者在拧紧上述2个螺杆时，未认真按照AMM手册
   要求使用力矩扳手，致使飞机起飞后燃调漏油并最终导致左发空中停车
   反映了工作者未能严格按照手册进行施工，缺乏安全意识，作风不严谨
   Score: 0.4063323736190796
   
   请输入标签（例如 '1,0,1'），或输入 'q' 结束: 1,0,0,0,0
   ```
6. 关于参数max_chunk_size和search()参数中k的选择。max_chunk_size越大一个chunk涵盖的信息就越多，但是一般问题都不会很长，一个短文本去匹配长文本天然就有困难，而max_chunk_size设置小了可能一个chunk中无法涵盖所有答案所需的信息。可以考虑增加top_n以增加输入大模型的信息。根据之前的经验，max_chunk_size*k在512-1024之间是好一点的。
7. 关于top_n的选择。诚然，top_n越大一次能标注的数据就越多，但是往往一段文本能匹配到的正样本就这么一两个，top_n大意味着标注了很多的负样本，暂不清楚这会对微调带来什么影响，我的倾向是尽量让正样本和负样本的数量平衡。这样的话top_n可以设在3-5这个区间。
8. 关于要标注多少条数据。max_chunk_size设为128时一共有18150个chunk，这个数还是很大的，如果全都标注一边的话短时间内时不可能的，建议可以先标个几百条看看效果，主要那些pdf都是一个领域的知识，应该不需要太多的数据以追求泛化性能。如果你们有gpt-4o之类的强模型api写个接口他来标也不是不行（滑稽）


***

# 基本介绍

本项目采用rag(**retrieval-augmented generation**)实现

主要流程为：

1. 加载和处理PDF文件
2. 文本嵌入与向量检索（主要就是将文档分成及各个chunk，每个chunk编码为一个向量，通过计算问题与每个向量之间的L2距离检索和问题相关的文段）
3. 将得到的文段作为prompt丢入大模型，让大模型输出问题的答案

 # 注意事项

记得将Final_Project_Documents文件夹单独导入，路径随便，只要更改rag.ipynb中下面的代码就行了

```
pdf_dir = 'Final_Project_Documents/test' #YOUR_PDF_DIR_PATH
```

可以随便挑个小的pdf文件作为测试，放到新建的test文件夹中

代码中采用了简易的gpt2作为大模型，效果不咋样，可能还需要调整，或者到时候直接把prompt丢入现成的大模型，又或者人肉搜索检索出来的文段得到答案。

***

可能需要安装的依赖

```
pip install transformers faiss-cpu sentence-transformers PyPDF2 
```

***

我试了下用SimCES来微调，效果很容易过拟合，而且需要较大的显存，时间关系没做多少次测试，可以考虑更换成更简易的预训练模型，然后微调的时候epoch和Lr调小一点看一下效果怎么样。这个项目主要还是需要**文本嵌入与向量检索**这一步的准确率

***

代码运行需要从huggingface下载预训练权重，一般需要科学上网
